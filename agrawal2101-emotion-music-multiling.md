Transformer-based approach towards music emotion recognition from lyrics
Yudhik Agrawal, Ramaguru Guru Ravi Shanker, Vinoo Alluri
43rd European Conference On Information Retrieval (ECIR) 2021
Journal reference: 	Lecture Notes in Computer Science, 12657 (2021) 167-175

# Abstract

* emotions from a given music track in the Music Information Retrieval (MIR)
* typically relied on acoustic features, social tags, and other metadata to
* The role of lyrics in music emotion recognition remains under-appreciated in
  spite of several studies reporting superior performance of music emotion
  classifiers based on features extracted from lyrics. In this study,
* we use the transformer-based approach model using XLNet as the base
  * has not been used to identify emotional connotations of music based on lyric
  * outperforms existing methods for multiple datasets
* We used a robust methodology to enhance web-crawlers' accuracy for extracting
  lyrics. This study has important
* applications involved in
  * playlist generation of music based on emotions in addition to improving
  * music recommendation systems
* Our multi-task setup helps in faster convergence and reduces model overfitting
  however, the single-task setup performs marginally better albeit at the
  expense of computational resources

# 1 Introduction

* Lyrics play a crucial role especially in
  * eliciting emotions [14], a vital factor contributing to musical reward [25],
  * reflecting user traits and tendencies [34] which in turn are related to
    musical preferences [26]. Despite a handful of
* studies reporting the superior performance of music emotion classifiers based
  on features extracted from lyrics than audio [16,38], the role of lyrics in
* advanced NLP in MIR has been used for
  * topic modelling [20],
  * identifying song structure via lyrics [13], and
  * mood classification [16]
  * In Music emotion recognition [23,38], typically traditional NLP approaches
    * word-level representations and embeddings, as opposed to contextualized
* Lyrics can be treated as narratives rather than independent words or sentences

# 5 Conclusion

* This study can help in improving applications like
  * playlist generation of music with similar emotions. Also,
  * hybrid music recommendation systems, which
    * utilize predominantly acoustic content-based and collaborative filtering
      approaches
* This approach can be extended in future to multilingual lyrics
