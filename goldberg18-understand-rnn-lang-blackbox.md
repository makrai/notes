#Q1: What is encoded/captured in a vector? 27

* Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, Y Goldberg
  Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks
  ICLR 2017
* Dieuwke Hupkes, Sara Veldhoen, and Willem Zuidema
  ...How Recurrent and Recursive Neural Networks Process Hierarchical Structure
  JAIR 2018
* Allyson Ettinger, Ahmed Elgohary, Philip Resnik
  Probing for semantic evidence of composition 
    by means of simple classification tasks 
  RepEval@ACL 2016
* Yonatan Belinkov, James Glass
  Analyzing Hidden Representations in End-to-End … Speech
  NIPS 2017
* F Dalvi; N Durrani; Hassan Sajjad; Yonatan Belinkov; Stephan Vogel
  Understanding and Improving Morpholog[y] in the NMT Decoder
  IJCNLP 2017
* Alexis Conneau, German Kruszewski, Guillaume Lample, Loïc Barrault, M Baroni
  What you can cram into a single vector: Probing sentence embeddings ...
  ACL 2018
* X Zhu, T Li, G Melo - Proceedings
  Exploring Semantic Properties of Sentence Embeddings
  ACL 2018

#Q2: what kinds of linguistic structures can be captured by an RNN? 43

* T Linzen
  Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies
  2016
* K Gulordava
  Colorless green recurrent networks dream hierarchically
  2018
* A Kuncoro
  LSTMs can learn syntax-sensitive dependencies well,
  But Modeling Structure Makes Them Better 
  ACL 2018
* Targeted Syntactic Evaluation of Language Models
  R Marvin
  EMNLP 2018
* R Futrell
  RNNs as psycholinguistic subjects: Syntactic state and grammatical dependency
  2018
* Can LSTM Learn to Capture Agreement? The Case of Basque
  Shauli Ravfogel, Francis M. Tyers, Yoav Goldberg 
  EMNLP 2018

#Q3: how did a given model reach a decision?  
  how is the architecture capturing the phenomena?

* Representation of linguistic form and function in recurrent neural networks
  A Kádár, G Chrupała, A Alishahi
  Computational Linguistics 2017
* Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context.
  Urvashi Khandelwal, He He, Peng Qi, Dan Jurafsky.
  ACL 2018
* Understanding Convolutional Neural Networks for Text Classification
  Alon Jacovi, Oren Sar Shalom, Yoav Goldberg
  EMNLP 2018

#Q4: when do models fail? what can't they do? 56

* Breaking NLI Systems with Sentences that Require Simple Lexical Inferences
  Max Glockner, Vered Shwartz, Yoav Goldberg 
  2018 ACL

#Q5 Q5: What is the representation power of RNNs? 78

* Recurrent Neural Networks as Weighted Language Recognizers
  Y Chen
  2017
* Rational Recurrences
  H Peng
  2018
* On the Practical Computational Power of Finite Precision RNNs for language rc 
  G Weiss, Goldberg, Yahav
  2018

#Q6 Extracting an FSA from an RNN 116

* Extracting Automata from Recurrent Neural Networks
    [Using Queries and Counterexamples](https://arxiv.org/abs/1711.09576)
  Gail Weiss, Yoav Goldberg, Eran Yahav
  ICML 2018

