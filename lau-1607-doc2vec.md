An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation
Jey Han Lau, Timothy Baldwin
1st Workshop on Representation Learning for NLP arXiv:1607.05368 [cs.CL]

# Abstract

* Recently, Le and Mikolov (2014) proposed doc2vec as
* an extension to word2vec (Mikolov+ 2013a) to learn document-level embeddings
* others have struggled to reproduce those results.
* This paper presents a rigorous empirical evaluation of doc2vec
  over two tasks.
  * compare doc2vec to two baselines and two SOTA document embedding methods.
* doc2vec performs robustly when using models trained on large external corp
* can be further improved by using pre-trained word embeddings.
* We also provide recommendations on hyper-parameter settings for general
* we release source code to
  induce document embeddings using our trained doc2vec models.
