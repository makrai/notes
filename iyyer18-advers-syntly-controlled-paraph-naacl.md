* adversarial examples (Goodfellow et al., 2015), which are generated by
  manually introducing lexical, pragmatic, and syntactic variation 
  not seen in the training set (Ettinger et al., 2017).  Robustness to such adversarial
  examples can potentially be improved by augmenting the training data, as
  shown by prior work that introduces rulebased lexical substitutions (Jia
  and Liang, 2017;
* General purpose syntactically controlled paraphrase generation 
  * We introduce the first learning approach for this problem
* Since no large-scale dataset of sentential paraphrases exists publicly, we
  follow Wieting et al.  (2017) and automatically generate millions of
  paraphrase pairs using neural backtranslation
* the top level of syntactic parses as transformation labels
* adversarial evaluation: the sentiment of the paraphrase should be different

#6 Qualitative Analysis

* Ebrahimi et al. (2017) ... substitution method for generating [lexical]
  adversarial examples
