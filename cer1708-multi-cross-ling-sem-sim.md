SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation
Daniel Cer, Mona Diab, Eneko Agirre, IÃ±igo Lopez-Gazpio, Lucia Specia
SemEval 2017

# Abstract

* Applications include machine translation (MT), summarization, generation,
  question answering (QA), short answer grading, semantic search, dialog and
  conversational systems
* The 2017 task focuses on multilingual and cross-lingual pairs with one
  sub-track exploring MT quality estimation (MTQE) data. The task
* strong participation from 31 teams, with 17 participating in all languages
* We summarize performance and review a selection of well performing methods.
  * common errors, providing insight into the limitations of existing models.
* the STS Benchmark is introduced as a new shared training and evaluation set
  carefully selected from the corpus of English STS shared task data
  (2012-2017).

# 8 STS Benchmark

* The STS Benchmark is a careful selection of the English data sets used in
  SemEval and `*`SEM STS shared tasks between 2012 and 2017. Tables 11 and 13
