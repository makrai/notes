How Linguistics Learned to Stop Worrying and Love the Language Models
Richard Futrell, Kyle Mahowald
arXiv:2500.17047 [cs.CL]

* LMs can contribute to fundamental questions about linguistic structure,
  language processing, and learning.
* They force us to rethink arguments that have been foundational in linguistics
* they do not replace linguistic structure and theory, 
* they serve as proofs of concept for gradient, usage-based approaches 

# 1 Intro

* It’s 1968, and Norm and Claudette are having lunch. Norm is explaining his
* Norm says he is interested in human language and the human mind, found HAL
  creepy, and isn’t sure why Claudette is so interested in building chatbots or
* all Claudette wants is a machine that talks and understands.  She doesn’t
  really care how it happens. Norm and Claudette have very different goals, but
* Fast forward to 2025. 
  * Norm has worked for decades on a variety of diverse languages, developing
    sophisticated theories of linguistic structure.
  * Claudette got more and more interested in engineering,
    amassing huge amounts of data, and training statistical models. Norm and
  * How relevant is it that the architecture of Claudette’s machines seems to
    have nothing to do with the structure of language as identified by Norm and
  * what if Norm was right about the nature of language— does that mean the
    machines aren’t actually as impressive as Claudette thinks, because they
    are relying on shallow pattern matching? 
  * Or are Claudette’s machines evidence that Norm’s theories were wrong?  More
  * a view: neural networks are no more relevant to linguistics than submarine
    engineering is to an ichthyologist—just because both submarines and fish
    can move underwater does not mean that you can learn much about one from
    studying the other.
* LMs have access to so much more data, that whatever they are doing is
  irrelevant for humans (Chomsky+ 2023; Fox and Katzir, 2024; Bolhuis+ 2024)
  * Some have denied that language models could learn the putatively key
    properties of human language, and thus are (Lan+ 2024; Fox and Katzir, 2024)
  * neural network sequence models could learn to approximate anything, so 
    ~> the fact that they seem to learn language is uninformative 
    (Rawski and Baumont, 2023; Moro+ 2023; Chomsky, 2023; Chomsky+ 2023;
    Collins, 2024; Bolhuis+ 2024)
    * LMs are like epicycles, the computational technique used by Ptolemy to
      predict the motions of the planets and the sun in a model that placed the
      Earth at the center of the universe (de Santillana, 1955; Flynn, 2013).
    * <~ epicycles can approximate any trajectory arbitrarily well (at the cost
      of great complexity), so the mere fact that they could be used to capture
* we: LMs do learn non-trivial aspects of linguistic structure, and 
  they do give important insights that change how we should think about
  language. As language scientists, we ignore them at our peril.
* An opposite approach is to dismiss traditional theories of linguistic struct,
  * either useless or of negative value in developing the only known systems
    that can actually use lang as humans do (Jelinek, 2004; Piantadosi, 2023)
  * this view is widespread in some engineering and application-focused communs
  * throws out hard-won analytical discoveries about the structure of language
* but
  * ? scientific theory of language, without 
  * ? a way to approach the question of why human language is the way it is, or
  * ? what the interesting questions are. Moreover, language models are
  * LM are currently most successful in English and other languages with
    internet-scale data (Blasi+ 2022). 
  * A more complete approach to the science of language will draw on the
    expertise of documentary linguists, sociolinguists, anthropologists, and
    community stakeholders, and it will integrate the insights from decades of
    linguistic inquiry.
* third view in linguistics, cognitive science, and philosophy
  (Smolensky, 1988; Pater, 2019; Portelance and Jasbi, 2023; McGrath+ 2024;
  Millière, 2024; Potts, 2025; Chesi, 2025): 
  * language models are not a complete theory of language—in fact, no one has
  * they are hugely informative about language and its structure, learning,
    processing, and relationship with the larger structure of the mind.
  * LMs have set off an intellectual explosion in cognitive science, machine
    learning, philosophy of mind, and other fields, in which 
    * longstanding ideas have been overturned; novel ideas are emerging; and
      disciplinary boundaries are dissolving. Linguistics has a chance to 
    * LMs can stand at the center of this huge intellectual ferment, and would
      be remiss to isolate itself intellectually on the basis that language
  * don’t look like existing theory. 
  * Language science already has contributed to the development of LMs
  * language models already have contributed insights about language.

# 2 Statistical models of language have outperformed expectations

## 2.1 A brief history of statistical language learning

## 2.2 Neural LMs learn nontrivial linguistic structure

# 3 The success of LMs is interesting for the science of language

## 3.1 Parallels between engineering models and cognition

## 3.2 Understanding LM success requires rethinking language learning

### 3.2.1 The significance of the learning problem in linguistics and cognitive science

### 3.2.2 The modern view on learning

### 3.2.3 The upshot for linguistic theory

### 3.2.4 The question of data quantity

## 3.3 Language models and linguistic traditions

### 3.3.1 The generative tradition of linguistics

### 3.3.2 The statistical tradition of linguistics

# 4 Where does that leave the science of language?

## 4.1 Linguistic structure is real

## 4.2 What LM interpretability can tell us about human language

## 4.4 What the inductive biases of LMs can tell us about language

## 4.6 Functional explanations for human language

## 4.7 Upshots for linguistics beyond language structure

# 5 Conclusion
