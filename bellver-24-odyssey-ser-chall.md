Multimodal Audio-Language Model for Speech Emotion Recognition
J Bellver, I Martín, JM Bravo, S Esteban, F Fernández-Martínez, LF D'Haro
Odyssey 2024

# Abstract

* Large Language Models (LLMs) with audio capabilities. Our proposed
* we combine an audio encoder, specifically the Whisper-large-v3 model [1],
  with LLMs Phi 1.5 [2] and Gemma 2b [3] to create a robust and effe classifier
* We compare the performance of our models against existing approaches,
* Whisper-large-V3 and Gemma 2b combination outperforming other alternatives
