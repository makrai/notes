* adversarial examples (Goodfellow+ 2015) are
  generated by manually introducing lexical, pragmatic, and syntactic variation
  not seen in the training set (Ettinger+ 2017).  
  * Robustness to such adversarial examples can potentially be improved by
    augmenting the training data, as shown by prior work that introduces
    rule-based lexical substitutions (Jia and Liang, 2017)
* General purpose syntactically controlled paraphrase generation
  * We introduce the first learning approach for this problem
* no large-scale dataset of sentential paraphrases exists publicly,
  ~> we follow Wieting+ (2017) and
  automatically generate millions of paraphrase pairs using
  neural backtranslation
* the top level of syntactic parses as transformation labels
* adversarial evaluation: the sentiment of the paraphrase should be different

#6 Qualitative Analysis

* Ebrahimi+ (2017) ... substitution method for generating [lexical]
  adversarial examples
