Position Information in Transformers: An Overview
Philipp Dufter, Martin Schmitt, Hinrich Sch√ºtze
Computational Linguistics, Volume 48, Issue 3 - September 2022

# Abstract

* Transformers are arguably the main workhorse in recent NLP research. By
  * invariant with respect to reordering of the input. However, language is
* we provide an overview and theoretical comparison of existing position meths
  * a vibrant and extensive research area; 
  * unified notation and systematization of different approaches along
    important model dimensions; 
  * characteristics of an application for selecting a position encoding; and 
  * provide stimuli for future research
