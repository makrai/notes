Understanding deep learning requires re-thinking generalization
Chiyuan Zhang; Samy Bengio; Moritz Hardt; Oriol Vinyals; Benjamin Recht
arxiv:16

# Abstract

* Specifically, our experiments establish that state-of-the-art convolutional
networks for image classification trained with stochastic gradient methods
easily fit a ran- dom labeling of the training data. This phenomenon is
qualitatively unaffected by explicit regularization, and occurs even if we
replace the true images by com- pletely unstructured random noise.
* We
corroborate these experimental findings with a theoretical construction showing
that simple depth two neural networks al- ready have perfect finite sample
expressivity as soon as the number of parameters exceeds the number of data
points as it usually does in practice.
