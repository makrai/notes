MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations
Soujanya Poria, Devamanyu Hazarika, N Majumder, G Naik, E Cambria, R Mihalcea
arXiv:1810.02508 [cs.CL]

http://affective-meld.github.io/

* Emotion recognition in conversations is a challenging task that has recently
  * large-scale multimodal multi-party emotional conversational database
    containing more than two speakers per dialogue was missing. Thus, we
* we: the Multimodal EmotionLines Dataset (MELD),
  an extension and enhancement of EmotionLines. MELD contains about 
  * 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each
  * annotated with emotion and sentiment labels, and encompasses audio, visual
    and textual modalities
  * several strong multimodal baselines and 
  * we show the importance of contextual and multimo info for emotion in conv
