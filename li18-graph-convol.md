Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning
Qimai Li, 1 Zhichao Han, 1,2 Xiao-Ming Wu 1âˆ—
The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)

# Abstract

* we show that the graph convolution of the GCN model is a special form of
  Laplacian smoothing, which is the key reason why GCNs work, but it also brings
  potential concerns of oversmoothing with many convolutional layers
* to overcome the limits of the GCN model with shallow architectures, we
  propose both co-training and self-training approaches to train GCNs
* Our approaches significantly improve GCNs in learning with very few labels,
  and exempt them from requiring additional labels for validation
* Extensive experiments on benchmarks have verified our theory and proposals
