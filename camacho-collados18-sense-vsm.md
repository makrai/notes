From Word to Sense Embeddings: A Survey on Vector Representations of Meaning
Jose Camacho-Collados and Mohammad Taher Pilehvar
arXiv:1805.04032v2 [cs.CL] 14 May 2018

#Abstract

* This survey is focused on semantic representation of meaning. 
* two main branches of sense representation, i.e., unsupervised and KBed
* this survey covers the main evaluation procedures and provides an analysis of

#1. Intro

* word embeddings [are] beneficial in [NLP] tasks, 
  * generalization power (Goldberg, 2016). A wide range of
  * applications have reported improvements upon integrating word embeddings,
    * Machine Translation (Zou, Socher, Cer, & Manning, 2013),
    * syntactic parsing (Weiss, Alberti, Collins, & Petrov, 2015),
    * text classification (Kim, 2014) and 
    * question answering (Bordes, Chopra, & Weston, 2014)

#2. Background 2

#3. Unsupervised Sense Representations

##3.1 Sense Representations Exploiting Monolingual Corpora

##3.2 Sense Representations Exploiting Multilingual Corpora

#4. Knowledge-based Semantic Representations

#5. Evaluation

#6. Analysis

##interpretability
##adaptability to different domains
##sense granularity
##compositionality and 
##integration into downstream applications.

#7. Conclusions
