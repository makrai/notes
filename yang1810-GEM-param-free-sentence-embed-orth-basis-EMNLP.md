Ziyi Yang, Chenguang Zhu, Weizhu Chen
Parameter-free Sentence Embedding via Orthogonal Basis
EMNLP-IJCNLP 2019

# Abstract

* Inspired by the Gram-Schmidt Process we build an orthogonal basis 
  of the subspace spanned by a word and its [sentence] context
* We model the meaning of a word in a sentence based on two aspects
  * relatedness to the word vector subspace already spanned by its context wrds
  * novel semantic meaning which ... introduced as a new basis vector perpendic
* method  to combine pre-trained word embeddings into sentence representations
  * based on orthogonal basis
  * zero parameters, along with efficient inference performance
* evaluate our approach on 11 downstream NLP tasks
  * superior performance compared with non-parameterized alternatives and it is
  * competitive to other approaches
    relying on either large amounts of labelled data or prolonged training time
