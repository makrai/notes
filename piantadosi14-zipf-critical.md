Steven T. Piantadosi
Zipf‚Äôs word frequency law in natural language:
  A critical review and future directions
Psychon Bull Rev (2014) 21:1112‚Äì1130

# Introduction

* Mandelbrot proposed and derived a generalization of this law that
  more closely fits the frequency distribution in language by
  ‚Äúshifting‚Äù the rank by an amount Œ≤ (Mandelbrot, 1953, 1962): ùëì(ùëü)‚àù1(ùëü+ùõΩ)ùõº (2)
  for Œ±‚Äâ‚âà‚Äâ1 and Œ≤‚Äâ‚âà‚Äâ2.7 (Mandelbrot, 1953, 1962; Zipf, 1936, 1949). This paper
* observed universally in languages, even in extinct and yet-untranslated
  languages like Meroitic (R. D. Smith, 2008).  
* the peculiarity of this law. It is certainly a
  * rule does not reference any aspect of each word‚Äôs meaning. Speakers generate
    speech by needing
  * the intricate processes of normal human language production conspire to
    result in a frequency distribution that is so mathematically simple‚Äîperhaps
    ‚Äúunreasonably‚Äù so (Wigner, 1960) 
* Derivations of Zipf‚Äôs law from more basic assumptions are numerous, both in
  language and in the many other areas of science where this law occurs (for
  overviews, see Farmer & Geanakoplos, 2006; Mitzenmacher, 2004; Newman, 2005;
  Saichev, Malevergne & Sornette, 2010). Explanations for the
  * many formal ideas, frameworks, and sets of assumptions. To give a brief
    picture of the range of explanations that have been worked out, such
  * random concatenative processes (Conrad & Mitzenmacher, 2004; Li, 1992;
    Miller, 1957),
  * mixtures of exponential distributions (Farmer & Geanakoplos, 2006),
    scale-invariance (Chater & Brown, 1999),
  * (bounded) optimization of entropy (Mandelbrot, 1953) or Fisher information
    (Hernando, Puigdom√®nech, Villuendas, Vesperinas & Plastino, 2009), the
  * invariance of such power laws under aggregation (Farmer & Geanakoplos, 2006)
  * multiplicative stochastic processes (see Mitzenmacher, 2004),
  * preferential reuse (Simon, 1955; Yule, 1944),
  * symbolic descriptions of complex stochastic systems (Corominas-Murtra &
    Sol√©, 2010),
  * random walks on logarithmic scales (Kawamura & Hatano, 2002),
  * semantic organization (Guiraud, 1968; D. Manin, 2008)
  * communicative optimization (Ferrer i Cancho, 2005a, b;
    Ferrer i Cancho & Sol√©, 2003; Mandelbrot, 1962;
    Salge, Ay, Polani, & Prokopenko, 2013; Zipf, 1936, 1949)
  * random division of elements into groups (Baek, Bernhardsson & Minnhagen
    2011)
  * first- and second-order approximation of most common (e.g., normal)
    distributions (Belevitch, 1959)
  * and optimized memory search (Parker-Rhodes & Joyce, 1956)
* question: true psychological account of the law. This means
  * an account that is connected to independently testable phenomena and
    mechanisms and fits with the psychological processes of word production and
    language use
  * very little such work on power laws in science (Stumpf & Porter, 2012)
  * the ability of a theory to derive the law provides very weak evidence for
    that account‚Äôs cognitive validity. Other evidence is needed
* This review intentionally steers clear from other statistical facts about text
  (e.g., Heap‚Äôs law, etc.) because these are thoroughly reviewed in other work
  (see Baayen, 2001; Popescu, 2009).  Instead, we focus here specifically on
* we provide experimental evidence that near-Zipfian word frequency
  distributions occur for novel words in a language production task

# The word frequency distribution is complex 3

# Empirical phenomena in word frequencies 5

## Semantics strongly influences word frequency

* many accounts of the law make no reference to meaning and semantics
  * for exceptions, see sections Semantic Accounts and Communicative Accounts
  * deriving it from principles independent of the content of language. But this
    * incompatible with the fact that even cross-linguistically, meaning is
      systematically related to frequency
  * Calude and Pagel (2011) reported an average inter-language correlation in
    log frequency of R = .53 (p < .0001) for [Swadesh] words

## Near-Zipfian distributions occur for fixed referential content

## Near-Zipfian distributions occur for naturally constrained meanings

## The fit of Zipfian distributions vary by category

## The distribution of word frequencies is not stationary

## Word frequency varies according to many forces

## Power laws arise from (almost) nothing

## Zipf‚Äôs law occurs in other human systems

# Models of Zipf‚Äôs law 11

# Conclusion and forward directions 16
