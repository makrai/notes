Evaluating Contextualized Language Models for Hungarian
Acs, Lévay, Nemeskey
MSYNY 2021

# Related work

* Probing is a popular method for exploring blackbox models.
  * Shi+ (2016): syntactic knowledge of neural machine translation models.
  * Belinkov+ (2017) probed NMT models for morphology. This work was followed by
  * similar probing papers
    (Belinkov+ 2017; Adi+ 2017; Hewitt and Manning, 2019; Liu+ 2019a;
    Tenney+ 2019b; Warstadt+ 2019; Conneau+ 2018a; Hupkes and Zuidema, 2018)
    * Warstadt Cao Grosu Peng Blix Nie Alsop Bordia Liu Parrish Wang Phang et al
      Investigating BERT’s knowledge of language: Five anal methods with NPIs
      EMNLP-IJCNLP 2019
    * Hupkes, D., Zuidema, W.
      Visualisation and ’diagnostic classifiers’ reveal
        how recurrent and recursive neural networks process hierarchical struct
      IJCAI (2018), https://doi.org/10.24963/ijcai.2018/796
  * limitations as knowledge extractors (Voita and Titov, 2020), and
  * low quality of silver data can also limit applicability of important probing
    techniques such as canonical correlation analysis (Singh+ 2019),
  * Multilingual BERT has been applied to a variety of multilingual tasks such
    * dependency parsing (Kondratyuk and Straka, 2019) or
    * constintuency parsing Kitaev+ (2019). mBERT’s multilingual capabilities
    * NER, POS and dependency parsing in dozens of language by Wu and Dredze
      (2019) and Wu and Dredze (2020). The surprisingly effective
    * multilinguality of mBERT was further explored by Dufter and Schütze (2020)
