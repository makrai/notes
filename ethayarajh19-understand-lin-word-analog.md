Towards Understanding Linear Word Analogies 
Kawin Ethayarajh, David Duvenaud, Graeme Hirst
ACL 2019 Florence, Italy

# Abstract

* We provide a formal explanation of this phenomenon
  without making the strong assumptions that past theories have made
  about the vector space and word distribution. Our theory has several
* implications
  * linear substructures exist in vector spaces because relations can be
    represented as ratios
    * Past work has conjectured that
    * we prove that this holds for SGNS
* We provide novel justification for the addition of SGNS word vectors by
  showing that
  it automatically down-weights the more frequent word, as weighting schemes do
  ad hoc
* Lastly, we offer an information theoretic interpretation of Euclidean distance
  in vector spaces, justifying its use in capturing word dissimilarity.
