Advances in Pre-Training Distributed Word Representations
T Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, Armand Joulin
LREC 2018

# Abstract

* a combination of known tricks that are however rarely used together
* outperform the current SOTA by a large margin on a number of tasks

# Introduction

* known modifications and data pre-processing strategies
  * position dependent features introduced by Mnih and Kavukcuoglu (2013),
  * phrase representations used in Mikolov+ (2013b) and the use of
  * subword information (Bojanowski+ 2017)
* We measure their quality on standard benchmarks:
  * syntactic, semantic and phrase-based analogies (Mikolov+ 2013b),
  * rare words dataset (Luong+ 2013), and
  * as features in a question answering pipeline
    on Squad question answering dataset (Rajpurkar+ 2016; Chen+ 2017)
