On Measuring Social Biases in Sentence Encoders
Chandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, Rachel Rudinger
NAACL 2019

# Abstract

* The Word Embedding Association Test shows that GloVe and word2vec word
  embeddings exhibit human-like implicit biases based on gender, race, and other
  social constructs (Caliskan+ 2017). Meanwhile, research on learning reusable
* sentence-level: we extend the Word Embedding Association Test to measure bias
* We test several sentence encoders, including SOTA methods e.g. ELMo &  BERT,
  * biases 
    * studied in prior work and two important biases 
    * that are difficult or impossible to test at the word level.  We observe
  * mixed results including suspicious patterns of sensitivity that suggest the
    testâ€™s assumptions may not hold in general. We conclude by 
* proposing directions for future work on measuring bias in sentence encoders.
