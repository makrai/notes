Ferrer i Cancho, Ramon
Decoding least effort and scaling in signal frequency distributions
Physica (2005)

#Abstract

* [jobban összefoglalja Manin (08)] 
* a general communication model where objects map to signals
* power function for the distribution of signal frequencies is derived
* relies on the satisfaction of the receiver (hearer) communicative needs
  when the entropy of the number of objects per signal is maximized
  * Evidence ... in a linguistic context ... reviewed and expanded
    (some of them with exponents clearly different from the typical
    `b \approx 2` of Zipf’s law)
* constraining just the number of interpretations of signals does not lead to
  scaling

#[nincsenek szakaszok]

* We assume a _general_ communication framework where signals are mapped to
  objects [1,2]
  * [1] M.A. Nowak, D.C. Krakauer, (1999) The evolution of language, Natl. Acad.
    [2] M.A. Nowak, J.B. Plotkin, D.C. Krakauer, (1999) 
      The evolutionary language game, J. Theor. Biol. 200 147–162.. 
  * For vervet monkeys, we have alarms calls ... and predators ... [3]
  * Unix computer commands, we have commands ... and the ... operations [6].
  * immune system, we have reactivity patterns ... and antigens [7,8]. We
* Word frequencies are usually modeled by a power function 
  * called Zipf’s law honoring G.K. Zipf, the linguist who made it popular [10]
  * We typically have b \approx 2 [11,12] but 
  * slight variations around b have been recorded [11].  There are some
  1. Schizophrenia with 1 < b < 2 [10].
  2. certain types of words (Fig.  1). We find 
    b = 3.35 for English nouns ... [13] whereas we find b = 1.94 for verbs
  3. The peripheral lexicon [12,14] ... two domains in p f : One domain with 
    * b \approx  2 for the most frequent[, core] words  and another domain with 
    * b \approx 3/2 for the less-frequent [, peripheral] words . The two
  4. Shakespearean ouvres with b = 1/6 [11]. This ... rather controversial
* questions:
  1. [what principles] form scaling in signal frequency distributions?
  2. Is such a principle [different from any explanation for] b = 2?
  3. How does information transfer depend on b?
* explanations have been proposed for scaling in word frequencies [17–29].
  17. R. Ferrer i Cancho, R.V. Solé, (2003) Least effort and the origins of sc
    * words are used according to their meaning
  18. B. Mandelbrot, 1953 An informational theory of the statistical structure
  19. H.A. Simon,(1955) On a class of skew distribution functions, Biometrika
  20. G.A. Miller,(1957) Some effects of intermittent silence, Am. J. Psychol.
  21. J.S. Nicolis,1991 Chaos and Information Processing, World Scientific,
  22. W. Li,(1992) Random texts exhibit Zipf’s-law-like word frequency distrib
  23. S. Naranan, V. Balasubrahmanyan,(1998) Models [in ling and CS]
  24. Harremoës & Topsoe,2002  ... hyperbolic distributions and entropy loss,
  25. W. Li,(1998) Letters to the editor, comments to Tsonis+ 97
  26. M.A. Montemurro,(2001) Beyond the Zipf–Mandelbrot law in quant ling. Phys
  27. L. Pietronero, E. Tosatti, V. Tosatti, A. Vespignani,(2001) ...
      distribution of number in nature: the laws of Benford and Zipf, Physica A
  28. S. Denisov,(1997) Fractal binary sequences: Tsallis thermodynamics and
  29. A.G. Bashkirov, A.V. Vityazev,(2000) ... for chaotic systems, Physica
  * require a discussion ... about distinguishing the causes of Zipf’s law (the
    true model(s)) from its consequences (the side-effect models). This is 
    * not the aim of the present paper
* Following ... [17], we assume that 
  words are chosen according to their meaning and that the 
  frequency of a word is a function of the objects eliciting it.
* Ref. [17] ... minimizing `lambda * E_D + 1-lambda * E_C`
  * linear combination of ... the hearer resp. speaker effort 
  * Sender and receiver needs are totally satisfied when l = 0 and l = 1; resp
  * [continuous] phase transition [30] separates [theses extremes]. 
  * Scaling consistent [with b 2 is found at some intermediate value] `l = l*`
  * where sender and receiver needs are at the maximum tension. 
  * We will refer to this model as the _dual least effort satisfaction model_
* Here, we show that scaling in word frequencies can be explained by only
  complying with receiver needs under a convenient maximization principle. 
  * We will refer to this model as the decoding least-effort model.
* We define H ; the entropy of the number of objects per signal, as
  * H is maximal at the point where scaling is found [17]
  * all signals will tend to have the same frequency if only receiver needs are
    satisfied
* a = 0 and therefore b -> 1 minimize not only E D but also maximize the
  potential information transfer [36,37], we may ask 
  * why human language has chosen a ~ 1 and therefore b ~ 2 as ... typical
  * [38–40] proposed [the answer is] that 
    human language is more a system of thought and mental representation 
    than a communication system
