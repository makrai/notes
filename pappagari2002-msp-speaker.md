x-vectors meet emotions: A study on dependencies between emotion and speaker recognition
Raghavendra Pappagari, Tianzi Wang, Jesus Villalba, Nanxin Chen, Najim Dehak
ICASSP 2020 Intl Conference on Acoustics, Speech, and Signal Proc arXiv:2002.05039 

# Abstract

* we explore the dependencies between speaker recognition and emotion recog. 
  * We first show that knowledge learned for speaker recognition can be reused
    for emotion recognition through transfer learning. 
  * Then, we show the effect of emotion on speaker recognition. For 
  * emotion recognition: a simple linear model is enough to obtain good
    performance on the features extracted from pre-trained models eg x-vector
  * Then, we improve emotion recognition performance by fine-tuning for emotion
    classification. We evaluated our 
* experiments on three different types of datasets: 
  IEMOCAP, MSP-Podcast, and Crema-D
  * pre+fine vs no pre: 30.40%, 7.99%, and 8.61% absolute improvement on
  * effect of emotion on speaker verification. We observed that 
    * speaker verification performance is prone to changes in test speaker
      emotions. We found that trials with 
    * angry utterances performed worst in all three datasets. We hope our
* Merci: osztályozás f-score 58.46
