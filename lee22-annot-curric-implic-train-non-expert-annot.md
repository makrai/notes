Annotation Curricula to Implicitly Train Non-Expert Annotators
Ji-Ung Lee, Jan-Christoph Klie, Iryna Gurevych
    Computational Linguistics, Volume 48, Issue 2 - June 2022

all code and data from the user study consisting of 2,400 annotations is availb

# Abstract

* Annotation studies often require annotators to familiarize themselves
  with the task, its annotation scheme, and the data domain
  * can be overwhelming in the beginning, mentally taxing, and induce errors
  * especially in citizen science or crowdsourcing scenarios: no domain expert
* we propose annotation curricula, a novel approach to implicitly train annors
  * formalizes annotation curricula for
  * sentence- and paragraph-level annotation tasks, defines an 
  * ordering strategy, and identifies
  * well-performing heuristics and interactively trained models on
  * three existing English datasets
  * proof of concept for annotation curricula in
    * identify the most fitting misconception for English tweets about Covid-19 
    * a carefully designed user study with 40 voluntary participants who are
* future: to specific tasks and expert annotation scenarios
