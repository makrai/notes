Dynamic Word Embeddings for Evolving Semantic Discovery
Zijun Yao, Yifan Sun, Weicong Ding, Nikhil Rao, Hui Xiong

* Word evolution refers to the changing meanings and associations of words
* we can infer social trends and language constructs 
* In this paper, we develop a 
  * dynamic statistical model to learn time-aware word vector representation.
    * solves the resulting "alignment problem".  This model is 
    * trained on a crawled NYTimes dataset. Additionally, we develop multiple
  * evaluation strategies of temporal word embeddings. Our qualitative and
  * consistently outperforms state-of-the-art temporal embedding approaches on
    both semantic accuracy and alignment quality. 
