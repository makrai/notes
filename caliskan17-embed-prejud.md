Semantics derived automatically from language corpora contain human-like biases
Aylin Caliskan, Joanna J. Bryson, Arvind Narayanan
Science  14 Apr 2017: Vol. 356, Issue 6334, pp. 183-186

* [embeddings contain] biases, whether morally neutral as toward insects or
  flowers, problematic as toward race or gender, or even simply veridical,
  reflecting the status quo distribution of gender with respect to careers or
  first names. Our methods hold promise for identifying and addressing sources
  of bias in culture, including technology
* popular online translation systems incorporate some of the biases we study
  (see the supplementary materials
* the nascent field of fairness in machine learning, which specifies and
  enforces mathematical formulations of nondiscrimination in decision-making
  * C. Dwork, M. Hardt, T. Pitassi, O. Reingold, R. Zemel,
    * Fairness through awareness,
    * Innovations in Theoretical Computer Science Conference (ACM, 2012)
  * M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, S.
    Venkatasubramanian,
    * Certifying and removing disparate impact
    * ACM SIGKDD 2015 (...Knowledge Discovery and Data Mining)


