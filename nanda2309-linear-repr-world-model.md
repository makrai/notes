Emergent Linear Representations in World Models of Self-Supervised Seq Models
Neel Nanda, Andrew Lee, Martin Wattenberg
arXiv:2309.00941 [cs.LG]

# Abstract

* How do sequence models represent their decision-making process?
* Othello-playing neural network learned nonlinear models of the board state
  (Li+ 2023)
* we provide evidence of a closely related linear representation of the board
  * probing for "my colour" vs "opponent's colour" may be a powerful way
    to interpret the model's internal state
  * allows us to control the model's behaviour with simple vector arithmetic
* Linear representations enable significant interpretability progress
* further exploration of how the world model is computed
