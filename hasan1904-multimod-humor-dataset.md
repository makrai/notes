UR-FUNNY: A Multimodal Language Dataset for Understanding Humor
Md Kamrul Hasan, Wasifur Rahman, Amir Zadeh, Jianyuan Zhong,
  Md Iftekhar Tanveer, Louis-Philippe Morency, Mohammed (Ehsan)Hoque
EMNLP-IJCNLP, 2019, 2046-2056 arXiv:1904.06618 [cs.LG]

publicly available for research

* Figure 1: UR-FUNNY
  * given a sequence of sentences: vision, acoustics, and transcript
  * goal: detect whether or not the sequence will trigger immediate laughter
    * ie whether or not the last sentence constitutes a punchline

# Abstract

* Humor is produced in a multimodal manner:
  words (text), gestures (vision) and prosodic cues (acoustic)
* unimodal humor detection is an established research area in NLP
  * the multimodal context is understudied
* we present a diverse multimodal dataset, called UR-FUNNY
