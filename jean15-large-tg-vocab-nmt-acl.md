On Using Very Large Target Vocabulary for Neural Machine Translation
SÃ©bastien Jean, Kyunghyun Cho, Roland Memisevic, Yoshua Bengio
2015 ACL

# Abstract

* as training complexity as well as decoding complexity increase
* proportionally to the number of target words
* In this paper, we propose a
  * method based on importance sampling
  * by selecting only a small subset of the whole target vocabulary

# 1 Introduction

* A usual practice is to construct a target vocabulary of the K most freq words
  * (a so-called shortlist), where
  * K is often in the range of
    * 30k (Bahdanau+ 2015) to
    * 80k (Sutskever+ 2014)

# 2 Neural Machine Translation and Limited Vocabulary Problem

# 3 Approximate Learning Approach to Very Large Target Vocabulary

# 4 Experiments

# 5 Conclusion
