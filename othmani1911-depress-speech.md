Towards Robust DNNs for Affect and Depression Recognition from Speech
Alice Othmani, Daoud Kadoch, Kamil Bentounes, Emna Rejaibi, R Alfred, A Hadid
ICPR CAIHA 2020 workshop arXiv:1911.00310 [cs.HC]

Code of EmoAudioNet is publicly available on GitHub

# Abstract

* Intelligent monitoring systems and affective computing applications
  * applications include assessment of affective states
    eg Major Depressive Disorder (MDD)
* MDD describes the constant expression of certain emotions: negative emotions
  (low Valence) and lack of interest (low Arousal)
* intelligent systems would enhance MDD diagnosis in its early stages
* we: EmoAudioNet, a new deep neural network architecture for emotion and
  depression recognition from speech
  * learns from both the time-frequency representation of the audio signal and
    the visual representation of its spectrum of frequencies
* very promising results in predicting affect and depression
* competitive with the SOTA methods according to several evaluation metrics on
  RECOLA and on DAIC-WOZ datasets
  in predicting arousal, valence, and depression
