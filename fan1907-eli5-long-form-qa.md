ELI5: Long Form Question Answering
Angela Fan, Yacine Jernite, E Perez, David Grangier, Jason Weston, Michael Auli
arXiv:1907.09190 [cs.CL]

* from the Reddit forum ``Explain Like I'm Five'' (ELI5) where an online
* Automatic and human evaluations show that an 
  abstractive model trained with a multi-task objective 
  outperforms conventional Seq2Seq, LM, as well as a strong extractive baseline
* best model is still far from human performance: prefer[ed] in over 86%

> dual challenges of isolating relevant information within long source
> documents and generating paragraph-length explanations
