Speech Technology for Unwritten Languages
Odette Scharenborg; Laurent Besacier; Alan Black; Mark Hasegawa-Johnson; al
IEEE 2020

* we present three speech technology applications that might be useful in an
  * end-to-end (E2E) speech-to-translation. In this task, a translation is
    * from raw speech of an unwritten language into a textual transcription of
      another language without any intermediate transcription [5], [58]. This
    * attractive for language documentation, where corpora are created and used
      consisting of audio recordings in the language being documented (the
      unwritten, source language) aligned with their translations in another
      (written) language, without a transcript in the source language [1], [7]
  * speech-to-image retrieval, a relatively new task [2], [18], [22], in which
    * images and speech are mapped to the same embedding space, and an image is
    * arguably similar to how children acquire their first language. This
    * attractive for, e.g., online shopping. A user might be interested in
      buying a coat, and ask for images of coats. The third task is
  * image-to-speech, a new speech technology task [23], [24], which is similar
    * interesting for social media applications.  Particularly in situations
* this paper learns an underlying semantic representation in order to
  * regenerate the speech signal, or its text translation, or to
    retrieve an image that depicts the same propositional content from a

# Section II background

# Section III the Deep Neural Network (DNN) architectures

* used for all experimental and baseline systems

# Section V describes the databases used for the experiments, and the methods
